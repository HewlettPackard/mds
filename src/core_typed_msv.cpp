/*
 *
 *  Managed Data Structures
 *  Copyright Â© 2016 Hewlett Packard Enterprise Development Company LP.
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU Lesser General Public License as published by
 *  the Free Software Foundation, either version 3 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU Lesser General Public License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public License
 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  As an exception, the copyright holders of this Library grant you permission
 *  to (i) compile an Application with the Library, and (ii) distribute the 
 *  Application containing code generated by the Library and added to the 
 *  Application during this compilation process under terms of your choice, 
 *  provided you also meet the terms and conditions of the Application license.
 *
 */

/*
 * core_msv.cpp
 *
 *  Created on: Nov 13, 2014
 *      Author: evank
 */

#include "core/core_typed_msv.h"
#include "core/core_kind_virt_inst.h"

namespace mds {
  namespace core {
    template <kind K>
    class typed_msv<K>::ross_vc : public value_chain {
      const gc_ptr<value> _value;

      using base = value_chain;
      using discriminator_type = typename value_chain::discriminator_type;
      using published_state = typename value_chain::published_state;

      using base::frozen_read_in;
        

      static gc_ptr<value> initial_value(const gc_ptr<view> &v,
                                         const gc_ptr<value_chain> &vc)
      {
        timestamp_t ts = v->context->publish_time_before(most_recent);
        return vc->value_at(ts-1);
      }

    public:
      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::read_only, view_type::snapshot, K);

      ross_vc(gc_token &gc,
              const gc_ptr<view> &v,
              const gc_ptr<value_chain> &p,
              discriminator_type d = discrim)
        : value_chain{gc, v, d}, _value{initial_value(v, p)}
      {
      }

      const static auto &descriptor() {
        using this_class = ross_vc;
        static gc_descriptor d =
          GC_DESC(ross_vc)
          .template WITH_SUPER(value_chain)
          .template WITH_FIELD(&this_class::_value)
          ;
        return d;
      }

      struct virtuals : value_chain::virtuals {
        using impl = ross_vc;
        void receive_conflict(core::value_chain *self, const gc_ptr<blocking_mod> &bm) override
        { 
          self->call_non_virtual(&impl::receive_conflict_impl, bm);
        }
        
        void do_rollup(core::value_chain *self, timestamp_t closed_ts) override {
          self->call_non_virtual(&impl::do_rollup_impl, closed_ts);
        }
        
        void prepare_for_publish(core::value_chain *self,
                                 const gc_ptr<msv> &in_msv,
                                 const gc_ptr<const published_state> &new_state) override
        {
          self->call_non_virtual(&impl::prepare_for_publish_impl, in_msv, new_state);
        }
        
        void add_contingent_child(core::value_chain *self,
                                  const gc_ptr<core::value_chain> &child) override
        {
          self->call_non_virtual(&impl::add_contingent_child_impl, child);
        }
        
        gc_ptr<core::value_chain> get_parent(const core::value_chain *self) const  override {
          return self->call_non_virtual(&impl::get_parent_impl);
        }
        
        gc_ptr<const published_state> pub_state_after(const core::value_chain *self,
                                                      timestamp_t ts) const  override
        {
          return self->call_non_virtual(&impl::pub_state_after_impl, ts);
        }
        
        gc_ptr<value> value_at(const value_chain *self,
                               timestamp_t ts) const override
        {
          return self->call_non_virtual(&impl::value_at_impl, ts);
        }
        
        val_type frozen_read_in(value_chain *self,
                                const gc_ptr<typed_msv> &msv) override
        {
          return self->call_non_virtual(&impl::frozen_read_in_impl, msv);
        }

        val_type modify_in(value_chain *self,
                           const gc_ptr<typed_msv> &msv,
                           modify_op op,
                           const val_type &arg,
                           ret_mode returning,
                           const gc_ptr<mod_condition> &guard) override
        {
          return self->call_non_virtual(&impl::modify_in_impl, msv,
                                        op, arg, returning, guard);
        }
        void add_conflicts_below(value_chain *self,
                                 const gc_ptr<blocking_mod> &bm,
                                 const gc_ptr<value_chain> &except) override
        {
          self->call_non_virtual(&impl::add_conflicts_below_impl, bm, except);
        }
      }; // virtuals


      void receive_conflict_impl(const gc_ptr<blocking_mod> &bm) {}
      void do_rollup_impl(timestamp_t closed_ts) {
        assert(ruts::fail("do_rollup() called on read-only snapshot"));
      }
      void prepare_for_publish_impl(const gc_ptr<msv> &in_msv,
                                    const gc_ptr<const published_state> &new_state)
      {
        assert(ruts::fail("prepare_for_publish() called on read-only snapshot"));
      }
      void add_contingent_child_impl(const gc_ptr<core::value_chain> &child)
      {
        /*
         * A read-only snapshot can be asked to add contingent
         * children (e.g., by a detached live or read-only-live
         * child), but it doesn't do anything with them.
         */
      }

      gc_ptr<value_chain>
      get_parent_impl() const {
        return nullptr;
      }
      
      
      gc_ptr<const published_state> pub_state_after_impl(timestamp_t ts) const {
        assert(ruts::fail("pub_state_after() called on read-only snapshot"));
      }
      gc_ptr<value> value_at_impl(timestamp_t ts) const {
        return _value;
      }
      val_type frozen_read_in_impl(const gc_ptr<typed_msv> &msv) {
        return _value == nullptr ? val_type{} : _value->val;
      }
      val_type modify_in_impl(const gc_ptr<typed_msv> &msv,
                              modify_op op, const val_type &arg,
                              ret_mode returning,
                              const gc_ptr<mod_condition> &guard)
      {
        if (op == modify_op::current_val || op == modify_op::frozen_current) {
          return frozen_read_in(msv);
        } else {
          throw read_only_context_ex{};
        }
      }
      void add_conflicts_below_impl(const gc_ptr<blocking_mod> &bm,
                                    const gc_ptr<value_chain> &except) 
      {
        assert(ruts::fail("add_conflicts_below() called on read-only snapshot"));
      }
        
    }; // ross_vc


    /*
     * The value we found was pointed to by a prior link with the
     * patched_arround_flag set.  This means that we can't trust that
     * it's the right one.  Note that this will only happen when we're
     * looking up because of a modification timestamp, not because
     * we're following a snapshot time.
     */
    struct uncertain_value_ex {
      const timestamp_t ts;
      uncertain_value_ex(timestamp_t t) : ts{t} {}
    };

    template <kind K>
    struct typed_msv<K>::non_ross_vc : value_chain {
      using base = value_chain;
        
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using base::get_context;
      using base::modify_in;
      using base::add_contingent_child;
      using base::call_virtual;
        
      using latest_ptr_t = versioned_gc_ptr<value, 6>;
      // Set when the latest value node has not been added since publication
      static constexpr typename latest_ptr_t::template flag_id<0> is_closed_flag{};
      // set when the latest value node indicates an added value
      // caching the value at publication.
      static constexpr typename latest_ptr_t::template flag_id<1> is_cached_flag{};
      // set when this value chain is on its parent's contingent child list.
      static constexpr typename latest_ptr_t::template flag_id<2> on_contingent_list_flag{};
      // set when a newly-created publishable snapshot chain sees that
      // the parent was modified before first read, indicating that it
      // should get a conflict on first read or pass one down if it
      // publishes without a read.  Also set when such a chain
      // receives a conflict while closed.
      static constexpr typename latest_ptr_t::template flag_id<3> parent_modified_flag{};
      // set when a closed publishable snapshot has passed down
      // conflicts to children, indicating that any further contingent children
      // should also get conflicts instead of being added
      static constexpr typename latest_ptr_t::template flag_id<4> passed_down_conflict_flag{};
      // indicates that a chain has publishable children.
      static constexpr typename latest_ptr_t::template flag_id<5> has_publishable_children_flag{};

      // Putting constant flags on the parent pointer just because it's cheap
      using parent_ptr_t = versioned_gc_ptr<value_chain, 2>;
      static constexpr typename parent_ptr_t::template flag_id<0> is_snapshot_flag{};
      static constexpr typename parent_ptr_t::template flag_id<1> is_publishable_flag{};

      typename latest_ptr_t::atomic_pointer _latest;
      const parent_ptr_t _parent;

      /* 
       * If a contingent child gets collected, that means the view
       * (and its context) is gone, so we don't need to worry about
       * conflicts below.
       */
      gc_atomic_stack<weak_gc_ptr<value_chain>> _contingent_children;

      /*
       * The pending modification only has to live as long as the
       * thread that started it cares.  Otherwise, it will have died
       * either before or after modifing the chain.  Either one is
       * okay.
       */
      std::atomic<weak_gc_ptr<modification>> _pending_modification;


      static parent_ptr_t compute_parent_ptr(const gc_ptr<view> &v,
                                             const gc_ptr<value_chain> &p)
      {
        parent_ptr_t pp = p;
        mod_type mt;
        view_type vt;
        std::tie(mt, vt) = v->context->get_mod_and_view_types();
        if (vt == view_type::snapshot) {
          pp[is_snapshot_flag] = true;
        }
        if (mt == mod_type::publishable) {
          pp[is_publishable_flag] = true;
        }
        return pp;
      }

      static latest_ptr_t initial_value(const gc_ptr<view> &v) {
        timestamp_t ts = v->context->last_stable_time();
        latest_ptr_t val = value::for_publish(ts, nullptr);
        val[is_closed_flag] = true;
        return val;
      }

      non_ross_vc(gc_token &gc,
                  const gc_ptr<view> &v,
                  const gc_ptr<value_chain> &p,
                  discriminator_type d)
        : base{gc, v, d}, _latest{initial_value(v)}, _parent{compute_parent_ptr(v, p)},
          _pending_modification{nullptr}
      {}

      const static auto &descriptor() {
        using this_class = non_ross_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          .template WITH_FIELD(&this_class::_latest)
          .template WITH_FIELD(&this_class::_parent)
          .template WITH_FIELD(&this_class::_contingent_children)
          .template WITH_FIELD(&this_class::_pending_modification)
          ;
        return d;
      }

      bool is_snapshot() const {
        return _parent[is_snapshot_flag];
      }

      bool is_publishable() const {
        return _parent[is_publishable_flag];
      }

      bool is_top_level() const {
        return _parent == nullptr;
      }

      gc_ptr<value> latest_value() const {
        return _latest;
      }

      struct virtuals : value_chain::virtuals {
        using impl = non_ross_vc;

        virtual void handle_task_dependencies(non_ross_vc *self,
                                              const gc_ptr<task> &read_task,
                                              const gc_ptr<task> &write_task)
        {
          // By default nothing to do.
        }

        virtual void roll_forward(non_ross_vc *self,
                                  timestamp_t &ts,
                                  const gc_ptr<value> &replacing,
                                  const gc_ptr<typed_msv> &in_msv) = 0;

        virtual void first_modification(non_ross_vc *self,
                                        const gc_ptr<task> &write_task) = 0;

        gc_ptr<core::value_chain> get_parent(const core::value_chain *self) const override final
        {
          return self->call_non_virtual(&impl::get_parent);
        }
        
        gc_ptr<value> value_at(const value_chain *self,
                               timestamp_t ts) const override final
        {
          return self->call_non_virtual(&impl::value_at, ts);
        }

        void add_contingent_child(core::value_chain *self,
                                  const gc_ptr<core::value_chain> &child) override
        {
          self->call_non_virtual(&impl::add_contingent_child_impl, child);
        }

        val_type frozen_read_in(value_chain *self,
                                const gc_ptr<typed_msv> &msv) override
        {
          return self->call_non_virtual(&impl::frozen_read_in_impl, msv);
        }

        val_type modify_in(value_chain *self,
                           const gc_ptr<typed_msv> &msv,
                           modify_op op,
                           const val_type &arg,
                           ret_mode returning,
                           const gc_ptr<mod_condition> &guard) override
        {
          return self->call_non_virtual(&impl::modify_in_impl, msv,
                                        op, arg, returning, guard);
        }

        void note_publishable_child(core::value_chain *self) override final
        {
          return self->call_non_virtual(&impl::note_publishable_child_impl);
        }
        
        void add_conflicts_below(value_chain *self,
                                 const gc_ptr<blocking_mod> &bm,
                                 const gc_ptr<value_chain> &except) override final
        {
          self->call_non_virtual(&impl::add_conflicts_below, bm, except);
        }

      }; // virtuals


      void handle_task_dependencies(const gc_ptr<task> &read_task,
                                    const gc_ptr<task> &write_task)
      {
        call_virtual(this, &virtuals::handle_task_dependencies,
                     read_task, write_task);
      }

      void roll_forward(timestamp_t ts,
                        const gc_ptr<value> &replacing,
                        const gc_ptr<typed_msv> &msv)
      {
        call_virtual(this, &virtuals::roll_forward, ts, replacing, msv);
      }

      void first_modification(const gc_ptr<task> &write_task)
      {
        call_virtual(this, &virtuals::first_modification, write_task);
      }

      gc_ptr<value_chain>
      get_parent() const {
        return _parent;
      }

      gc_ptr<value> value_before(timestamp_t ts) const {
        bool last_val_patched = false;
        gc_ptr<value> head = _latest;
        timestamp_t last_ts = 0;
        for (typename value::prior_ptr_t v = head;
             v != nullptr;
             v = v->prior)
          {
            timestamp_t this_ts = v->timestamp();
            if (this_ts < ts) {
              if (last_val_patched) {
                throw uncertain_value_ex{last_ts};
              }
              return v;
            }
            last_val_patched = v[value::patched_around_flag];
            last_ts = this_ts;
          }
        if (last_val_patched) {
          throw uncertain_value_ex{last_ts};
        }
        return nullptr;
      }

      gc_ptr<value> value_at(timestamp_t ts) const {
        timestamp_t next_ts = ts == most_recent ? ts : ts+1;
        gc_ptr<value> v = value_before(next_ts);
        if (v != nullptr && !v->marks_publish()) {
          return v;
        }
        /*
         * We didn't find one.  When we look up, if this is a
         * snapshot view, we need to reset the timestamp to the
         * last publish time prior to the time we're looking for.
         * Note that this might not be the one from the node we're
         * looking at, although it will be no earlier than it.
         */
        if (is_top_level()) {
          return nullptr;
        }

        timestamp_t pts = ts;
        if (is_snapshot()) {
          timestamp_t pub_ts = (ts==most_recent)
            ? get_context()->last_stable_time()
            : get_context()->publish_time_before(ts+1);
          // std::cout << "Pub time before << " << ts << " is " << pub_ts << std::endl;
          if (v != nullptr && v->timestamp() > pub_ts) {
            /*
             * If this is a snapshot, it's possible that v marks a
             * roll-forward rather than a roll-up.  In this case, we
             * want to look up as of that time, unless there have been
             * subsequent roll-ups.
             */
            pts = v->timestamp();
            // std::cout << "Saw roll-forward to " << pts << std::endl;
          } else {
            assert(pub_ts > 0);
            pts = pub_ts-1;
          }
        }
        // std::cout << "Looking upward from "
        //           << ts << " (" << base::_view << ")"
        //           << " to "
        //           << pts << " (" << get_parent()->get_view() << ")"
        //           << std::endl; 

        // NOTE: We need to get a value node from our parent, even if it's a ROSS.

        gc_ptr<value> pv = get_parent()->value_at(pts);
        // if (pv == nullptr) {
        //   std::cout << "Got NULL" << std::endl;
        // } else {
        //   std::cout << "Got " << pv->val << std::endl;
        // }
        /*
         * If we're looking for the most recent value and the value
         * on this chain has changed, then it must have opened (and
         * maybe closed).  So we can walk down the chain until we
         * find an open one.  If we hit the one we got before, there
         * was no open value, so we use what we got from the parent.
         * If not, we use the most recent open value.
         */
        if (ts == most_recent) {
          for (gc_ptr<value> v2 = latest_value();
               v2 != v;
               v2 = v2->prior)
            {
              if (!v2->marks_publish()) {
                return v2;
              }
            }
        }
        return pv;
      }

      void add_contingent_child_impl(const gc_ptr<core::value_chain> &child) {
        /*
         * This works for all live value chains.  Snapshots will override
         */
        add_to_cc_list(child);
        ensure_on_cc_list([this](const latest_ptr_t p) {
            /*
             * If we're open, we can stay off (since any incoming
             * conflicts will be blocked), and if the contingent
             * children list has been cleared, we can stay off (since
             * the one we added must've gotten the conflict).  We
             * don't need to reread the (atomic) _latest ptr, since it
             * will be what was passed in.
             */
            return p[is_closed_flag] && has_contingent_children();
          });
      }

      val_type frozen_read_in_impl(const gc_ptr<typed_msv> &msv) 
      {
        gc_ptr<value> vn = latest_value();
        if (vn != nullptr && !vn->marks_publish()) {
          // std::cout << "Read found latest: "
          //           << vn->val << " @ " << vn->timestamp()
          //           << std::endl;
          return vn->val;
        }
        // std::cout << "Read didn't find value, trying modify" << std::endl;
        /*
         * If we can't read an open value, we'll have to do it as a
         * modification to cache.  (It may be opened by the time we
         * get there, but that's okay.)
         */
        return modify_in(msv, modify_op::frozen_current, val_type{});
      }

      val_type modify_in_impl(const gc_ptr<typed_msv> &msv,
                              modify_op op, const val_type &arg,
                              ret_mode returning,
                              const gc_ptr<mod_condition> &guard)
      {
        gc_ptr<modification> mod = make_gc<modification>(GC_THIS, msv, returning,
                                                         op, arg, guard);
        install_and_run(mod);
        return get_context()->shadowed_val(mod->get_value());
      }

      void note_publishable_child_impl() {
        _latest.set_flag(has_publishable_children_flag);
      }

      bool is_closed() const {
        return _latest.flag(is_closed_flag);
      }

      bool caches_parent_value() const {
        return _latest.flag(is_cached_flag);
      }



      bool parent_modified() const {
        return _latest.flag(parent_modified_flag);
      }

      void set_parent_modified() {
        _latest.set_flag(parent_modified_flag);
      }

      bool has_publishable_children() const {
        return _latest.flag(has_publishable_children_flag);
      }

      bool passed_down_conflict() const {
        return _latest.flag(passed_down_conflict_flag);
      }

      void set_passed_down_conflict() {
        _latest.set_flag(passed_down_conflict_flag);
      }

      void block_inbound_publication(const gc_ptr<blocking_mod> &bm) const {
        if (has_publishable_children()) {
          get_context()->block_inbound_publication(bm);
        }
      }

      template <typename Then, typename Else>
      auto if_closed(const gc_ptr<blocking_mod> &bm, Then &&then_fn, Else &&else_fn) const
      {
        if (is_closed()) {
          if (bm != nullptr) {
            block_inbound_publication(bm);
          }
          /*
           * It's possible that it opened again while we were
           * blocking.
           */
          if (bm == nullptr || is_closed()) {
            return std::forward<Then>(then_fn)();
          }
        }
        return std::forward<Else>(else_fn)();
      }
                           
      /*
       * bm is null on publish.
       */
      void add_conflicts_below(const gc_ptr<blocking_mod> &bm,
                               const gc_ptr<value_chain> &except = nullptr)
      {
        // std::cout << "Adding conflicts below " << GC_THIS
        //           << " except " << except << std::endl;
        /*
         * Once everybody's been taken care of, they're no longer
         * contingent children.  We pop as we go to handle any that
         * are added while we're working.  
         */
        _contingent_children.apply_and_pop_all([=](const auto &child_wp) {
            auto child = child_wp.lock();
            if (child != nullptr && child != except) {
              // std::cout << "Adding conflict to " << child << std::endl;
              child->receive_conflict(bm);
            } else {
              // std::cout << "Skipping " << child << std::endl;
            }
          });
        /*
         * TODO: Need to add except back.  Not sure if this can simply
         * be done by calling add_contingent_child().  I'm going to
         * assume it can, but this should be checked.
         */
        if (except != nullptr) {
          add_contingent_child(except);
        }
      }

      void add_to_cc_list(const gc_ptr<core::value_chain> &child) {
        /*
         * The child is necessarily one from this MSV type.
         */
        gc_ptr<value_chain> c = std::static_pointer_cast<value_chain>(child);
        _contingent_children.push(c);
      }

      bool has_contingent_children() const {
        /*
         * For now, I'm not going to go through and check that they
         * all lock non-null.  It's almost certainly not worth the
         * work.
         */
        return !_contingent_children.empty();
      }

      template <typename Fn>
      bool ensure_on_cc_list(Fn&& pred) {
        if (is_top_level()) {
          return false;
        }

        bool added = false;
        typename latest_ptr_t::version_value last_version;
        //        return _latest.try_update([&pred](const latest_ptr_t p) {
        return _latest.try_update([pred=std::forward<Fn>(pred)](const latest_ptr_t p) {
            return !p[on_contingent_list_flag] && pred(p);
          },
          [&, this](latest_ptr_t p){
            if (!added || p.version() != last_version) {
              /*
               * If we've added (at least) once and the version number
               * hasn't changed (indicating that note_off_cc_list()
               * hasn't been called), then we're still on the list, so
               * we don't have to do it again.  Otherwise, it's
               * possible that add_conflicts_below() has been called
               * and we're no longer there, so if we set the flag
               * without re-adding, we'd be wrong.  Since we can't
               * tell, we'll assume that it's better to be correctly
               * marked and put ourselves on again.
               */
              _parent->add_contingent_child(GC_THIS);
              added = true;
              last_version = p.version();
            }
            /*
             * If we swap out here and add_conflicts_below() is
             * called, note_off_cc_list() will increment the version
             * number, so this update will fail, and we'll go around
             * againt.
             */
            p[on_contingent_list_flag] = true;
            return p;
          });
      }
      bool ensure_on_cc_list() {
        return ensure_on_cc_list([](const auto &){ return true; });
      }

      void note_off_cc_list() {
        _latest.update([](latest_ptr_t p) {
            p.version()++;
            p[on_contingent_list_flag] = false;
            return p;
          });
      }

      template <typename T>
      vd_value<T> roll_up_val(const vd_value<T> &val) {
        gc_ptr<view> child_view = val.in_view;
        if (child_view == nullptr) {
          return vd_value<T>();
        } else {
          gc_ptr<view> my_view = child_view->parent;
          assert(my_view->context == get_context());
          return vd_value<T>(val.value, my_view);
        }
      }

      template <typename T>
      const T &roll_up_val(const T &val) {
	return val;
      }
      

      template <typename ValFn, typename TaskFn>
      void receive_rollup(timestamp_t closed_ts, ValFn&& vfn, TaskFn&& tfn,
                          const gc_ptr<redo_task_set> &rts)
      {
        latest_ptr_t latest = _latest.contents();
        if (latest->timestamp() >= closed_ts) {
          /*
           * If we have a later value, somebody else closed it.  We
           * make sure that changing the timestamp is the last thing
           * we do.
           */
          return;
        }
        val_type child_val = std::forward<ValFn>(vfn)();
        gc_ptr<task> t = std::forward<TaskFn>(tfn)();

        val_type val = roll_up_val(child_val);
        //        val_type val = get_context()->shadowed_val(child_val);

        /*
         * The value is logically rolled up as the last thing that
         * happened at the timestamp before.
         */
        timestamp_t rollup_ts = closed_ts-1;
        /*
         * If there was a value at that timestamp, we can patch around it.
         */
        gc_ptr<value> prior_val = latest;
        bool can_patch_around_latest = false;
        /*
         * If we're closed or there's a snapshot between, we can't
         * prune.  (Strictly speaking, we could if we were the same
         * task and we had the same value.)
         */
        if (latest[is_closed_flag]) {
          // std::cout << "Can't patch around closed marker during roll-up" << std::endl;
        } else if (snapshot_between(rollup_ts, prior_val->timestamp())) {
          // std::cout << "Can't patch around snapshot in [" << rollup_ts
          //           << ", " << prior_val->timestamp() << "] during roll-up" << std::endl;
        } else if (t == prior_val->write_task) {
          /*
           * The chain is open and was last written in this task.
           * If there's no snapshot between , we don't have to worry
           * about roll-forward, so we can prune around.
           */
          can_patch_around_latest = true;
          // std::cout << "Patching around same task val during roll-up" << std::endl;
        } else if (!is_publishable()) {
          /*
           * If we're not publishable, we don't have to worry about
           * roll-forward, so we can patch around.
           */
          can_patch_around_latest = true;
          // std::cout << "Patching around val in non-pub VC during roll-up" << std::endl;
        } else {
          // std::cout << "Can't patch around val during roll-up" << std::endl;
        }
        if (can_patch_around_latest) {
          prior_val = prior_val->prior;
          // std::cout << "Patched around val during roll-up" << std::endl;
        }
        gc_ptr<value> new_v = make_gc<value>(rollup_ts, val, prior_val, prior_val != latest, t);

        // std::size_t len = 0;
        // for (auto p = new_v; p != nullptr; p=p->prior) {
        //   len++;
        // }
        // std::cout << "Roll-up VC length == " << len << std::endl;

        // std::cout << "Rolling up " << child_val
        //           << " to " << val
        //           << " in " << GC_THIS
        //           << std::endl;

        /*
         * We have to handle the dependencies before we actually
         * change the latest pointer, because otherwise a racing
         * roll-up will see the new timestamp and short circuit,
         * potentially leaving it undone or continuing before it's
         * done.
         *
         * TODO: What happens if in between the short circuit check
         * and now somebody else finishes, the chain's rts is cleared,
         * and then we call handle_task_dependencies(), which resets
         * it? (BUG)
         */
        if (rts != nullptr) {
          handle_task_dependencies(rts->source_task(), t);
        }

        /*
         * If we fail to install, that means that somebody else
         * already did.  That's okay, because that means that the
         * roll-up has been taken care of.
         */
        _latest.change_using(latest, [new_v](latest_ptr_t p) {
            p.pointer() = new_v;
            p[is_closed_flag] = false;
            p[is_cached_flag] = false;
            return p;
          });
      }
                          
      void install(const gc_ptr<modification> &mod) {
        while (true) {
          auto rr = ruts::try_change_value(_pending_modification, nullptr, mod);
          if (rr) {
            return;
          }
          /*
           * There was already one there.
           */
          gc_ptr<modification> current = rr.prior_value.lock();
          if (current == mod) {
            /*
             * Two threads tried to install the same event (as part of its execution)
             */
            return;
          }
          current->perform();
          /*
           * The run() method will call uninstall().
           */
        }
      }
      void install_and_run(const gc_ptr<modification> &mod) {
        install(mod);
        mod->perform();
      }

      void uninstall(const gc_ptr<modification> &mod) {
        ruts::try_change_value(_pending_modification, mod, nullptr);
        /*
         * If that failed, it means that some other thread removed it.
         */
      }
      
      gc_ptr<value> needed_value(modify_op op, ret_mode returning, timestamp_t ts) {
        switch (op) {
        case modify_op::roll_forward:
          return nullptr;
        case modify_op::set:
          if (returning == ret_mode::resulting_val)
            {
              return nullptr;
            }
          // FALLTHRU
        default:
          /*
           * Everything else needs the current value.
           */
          return value_at(ts);
        }
      }

      gc_ptr<value> ensure_value(const val_type &val,
                                 timestamp_t ts,
                                 const gc_ptr<value> &replacing,
                                 const gc_ptr<task> &write_task,
                                 const gc_ptr<msv> &in_msv,
                                 bool modifies)
      {
        auto latest = _latest.contents();
        if (latest.pointer() != replacing) {
          /*
           * Somebody else must've finished for us and another value
           * was added.  Nothing to do here.
           *
           * TODO: What if we went to sleep just after entering
           * ensure_value(), somebody else finished this one, and
           * another one asserted a value with the same timestamp.
           * We would then put ours in, and the values would appear
           * to go backwards.  If a thread did three reads, they
           * might read this one, the other one, and then this one
           * again.  This is wrong.  But it would take a sleep after
           * we read the phase but before we read the value of
           * _latest.  If that happens after we read from _latest,
           * we'll fail the update.
           */
          return nullptr;
        }
        gc_ptr<value> prior = replacing;
        bool is_cached = latest[is_cached_flag];
        bool is_closed = latest[is_closed_flag];
        bool caches_parent = !modifies && (is_cached || is_closed);

        bool context_notified = !is_closed && !is_cached;
        bool task_notified = false;
        bool same_task = replacing->write_task == write_task;

        bool can_patch_around_latest = false;

        /*
         * If we're closed or there's a snapshot between, we can't
         * prune.  (Strictly speaking, we could if we were the same
         * task and we had the same value.)
         */
        if (!is_closed && !snapshot_between(ts, replacing->timestamp())) {
          if (same_task) {
            /*
             * The chain is open and was last written in this task.
             * If there's no snapshot between , we don't have to worry
             * about roll-forward, so we can prune around.
             *
             * We've told the task unless we were cached.
             */
            task_notified = !is_cached;
            if (val == replacing->val) {
              /*
               * The value hasn't changed.  So there's nothing to do.
               * Either we've already notified the task and the
               * context or we're cached and this would be cached,
               * too.  So we can just return.
               */
              return nullptr;
            }
            can_patch_around_latest = true;
          } else if (!is_publishable()) {
            /*
             * If we're not publishable, we don't have to worry about
             * roll-forward, so we can patch around.
             */
            can_patch_around_latest = true;
          }
        }
        /*
         * The value has changed, but we're in the same
         * timestamp, so we can patch around.  [TODO: Check on
         * whether read-in-snapshot is still necessary.]
         */
        if (can_patch_around_latest) {
          // std::cout << "Patched around val during assignment" << std::endl;
          prior = replacing->prior;
        }
       
        if (!task_notified && is_publishable()) {
          /*
           * If there are notifications needed, we need to do them
           * before we add the value.  Otherwise, if we fail after
           * adding the value, the next task will return early,
           * and we'll never get there.
           */
          gc_ptr<modified_value_chain>
            mvc = make_gc<modified_value_chain>(GC_THIS, in_msv);
          write_task->add_modification(mvc);
          if (!context_notified) {
            // std::cout << "Adding MVC for " << GC_THIS
            //           << " to " << write_task->get_context()
            //           << std::endl;
            write_task->get_context()->add_modification(mvc);
          // } else {
          // std::cout << "No MVC for " << GC_THIS
          //           << " because context already notified"
          //           << std::endl;
          }
        // } else if (task_notified) {
        //   std::cout << "No MVC for " << GC_THIS
        //             << " because task already notified"
        //             << std::endl;
        // } else {
        //   std::cout << "No MVC for " << GC_THIS
        //             << " because task not publishable"
        //             << std::endl;
        }

        latest_ptr_t new_value = make_gc<value>(ts, val, prior, prior != replacing, write_task);
        new_value[is_cached_flag] = caches_parent;
        bool called_first_modification = !is_closed;
        _latest.try_update([=](latest_ptr_t p) {
            return p.pointer() == replacing;
          },
          [=, &called_first_modification](latest_ptr_t p) {
            p.pointer() = new_value;
            p[is_closed_flag] = false;
            p[is_cached_flag] = caches_parent;
            if (!called_first_modification) {
              first_modification(write_task);
              called_first_modification = true;
            }
            return p;
          });
        /*
         * If that failed, it meant somebody else beat us to it.
         */
        return new_value;

        /*
         * TODO: We need to make a call to (1) add the RTS is set up
         * and (2) induce a conflict if parent-modified flag is set.
         */
      }
      

    }; // non_ross_vc

    template <kind K>
    struct typed_msv<K>::unpub_vc : non_ross_vc {

      using base = non_ross_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      using base::add_conflicts_below;
      using base::note_off_cc_list;
      using base::if_closed;
        
      unpub_vc(gc_token &gc,
               const gc_ptr<view> &v,
               const gc_ptr<value_chain> &p,
               discriminator_type d)
        : base{gc, v, p, d}
      {}

      const static auto &descriptor() {
        using this_class = unpub_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = unpub_vc;
        void do_rollup(core::value_chain *self, timestamp_t closed_ts) override {
          self->call_non_virtual(&impl::do_rollup_impl, closed_ts);
        }
        
        void prepare_for_publish(core::value_chain *self,
                                 const gc_ptr<msv> &in_msv,
                                 const gc_ptr<const published_state> &new_state) override
        {
          self->call_non_virtual(&impl::prepare_for_publish_impl, in_msv, new_state);
        }

        void receive_conflict(core::value_chain *self, const gc_ptr<blocking_mod> &bm) override 
        { 
          self->call_non_virtual(&impl::receive_conflict_impl, bm);
        }
        void roll_forward(non_ross_vc *self,
                          timestamp_t &ts,
                          const gc_ptr<value> &replacing,
                          const gc_ptr<typed_msv> &msv) override
        {
          self->call_non_virtual(&impl::roll_forward_impl, ts, replacing, msv);
        }

      }; // virtuals

      void do_rollup_impl(timestamp_t closed_ts) {
        assert(ruts::fail("do_rollup() called on unpublishable value chain"));
      }
      void prepare_for_publish_impl(const gc_ptr<msv> &in_msv,
                               const gc_ptr<const published_state> &new_state)
      {
        assert(ruts::fail("prepare_for_publish() called on unpublishable value chain"));
      }

      void receive_conflict_impl(const gc_ptr<blocking_mod> &bm) {
        if_closed(bm,
                  [&,this]() {
                    add_conflicts_below(bm);
                  },
                  [this](){
                    // Nothing to do.  (We can't publish, so no conflict here.)
                  });
        note_off_cc_list();
      }

      void roll_forward_impl(timestamp_t ts,
                             const gc_ptr<value> &,
                             const gc_ptr<typed_msv> &)
      {
        assert(ruts::fail("roll_forward() called on unpublishable value chain"));
      }

  
    }; // unpub_vc

    template <kind K>
    struct typed_msv<K>::pub_vc : non_ross_vc {

      using base = non_ross_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      using base::is_closed;
      using base::get_context;
      using base::_latest;
      using base::get_parent;
      using base::is_closed_flag;
      using base::is_snapshot;
      using base::ensure_on_cc_list;
      using base::is_cached_flag;
      using base::parent_modified_flag;
      using base::passed_down_conflict_flag;
      using base::caches_parent_value;
      using base::latest_value;
      using base::has_contingent_children;
      using base::modify_in;
      using base::ensure_value;

      using redo_task_set_ptr_t = versioned_gc_ptr<redo_task_set, 1>;
      static constexpr redo_task_set_ptr_t::flag_id<0> has_conflict_flag{};
        
      redo_task_set_ptr_t::atomic_pointer _redo_task_set;

      pub_vc(gc_token &gc,
             const gc_ptr<view> &v,
             const gc_ptr<value_chain> &p,
             discriminator_type d)
        : base{gc, v, p, d}
      {
        p->note_publishable_child();
      }

      const static auto &descriptor() {
        using this_class = pub_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          .template WITH_FIELD(&this_class::_redo_task_set)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = pub_vc;

        gc_ptr<const iso_context::published_state> pub_state_after(const core::value_chain *self,
                                                                   timestamp_t ts) const override
        {
          return self->call_non_virtual(&impl::pub_state_after_impl, ts);
        }

        void do_rollup(core::value_chain *self, timestamp_t closed_ts) override {
          self->call_non_virtual(&impl::do_rollup_impl, closed_ts);
        }

        void prepare_for_publish(core::value_chain *self,
                                 const gc_ptr<core::msv> &in_msv,
                                 const gc_ptr<const published_state> &new_state) override
        {
          self->call_non_virtual(&impl::prepare_for_publish_impl, in_msv, new_state);
        }

        void handle_task_dependencies(non_ross_vc *self,
                                      const gc_ptr<task> &read_task,
                                      const gc_ptr<task> &write_task) override final
        {
          self->call_non_virtual(&impl::handle_task_dependencies, read_task, write_task);
        }
        
        void roll_forward(non_ross_vc *self,
                          timestamp_t &ts,
                          const gc_ptr<value> &replacing,
                          const gc_ptr<typed_msv> &msv) override
        {
          self->call_non_virtual(&impl::roll_forward_impl, ts, replacing, msv);
        }

        void prepare_for_redo(core::value_chain *self,
                              const gc_ptr<modified_value_chain> &mvc) override
        {
          self->call_non_virtual(&impl::prepare_for_redo_impl, mvc);
        }
        
      }; // virtuals

      gc_ptr<const iso_context::published_state> pub_state_after_impl(timestamp_t ts) const
      {
        if (is_closed()) {
          return get_context()->first_publish_after(ts);
        } else {
          return nullptr;
        }
      }

      void prepare_for_publish_impl(const gc_ptr<core::msv> &in_msv,
                                    const gc_ptr<const published_state> &new_state)
      {
        // std::cout << "Preparing to publish " << GC_THIS << std::endl;
        if (is_closed() || caches_parent_value()) {
          /*
           * If we're closed, then publishing won't change our
           * parent.  If we're open, but we cache a value read from
           * the parent, then either the parent hasn't changed since
           * we read it, in which case publishing won't change the
           * value, or it has, in which case we got (or are about to
           * get) a conflict and our publish won't succeed.
          //  */
          // if (is_closed()) {
          //   std::cout << "It was closed" << std::endl;
          // }
          // if (caches_parent_value()) {
          //   std::cout << "It cached its parent's value" << std::endl;
          // }
          return;
        }
        /*
         * Otherwise, our publishing induces conflicts in our parent's
         * contingent children except for us.  Then we add a rollup.
         */
        gc_ptr<value_chain> p = get_parent();
        // std::cout << "Adding conflicts below parent " << p << std::endl;
        p->add_conflicts_below(nullptr, GC_THIS);
        in_msv->add_rollup(GC_THIS, get_context(), new_state);
      }


      void close_chain(timestamp_t closed_ts,
                       const gc_ptr<value> &old_val,
                       redo_task_set_ptr_t rts)
      {
        /*
         * Rolling up or forward clears the redo task set.  If it's
         * changed since we looked, somebody else must've done the
         * roll-up and already cleared.  But it's okay if somebody
         * changed a flag, since we may be racing a parent
         * modification that, e.g., sets the parent-modified flag.
         *
         * TODO: Ensure that there isn't a potential race with a
         * modification adding one.  I don't think there should be,
         * because they would've had to do the roll-up before the
         * modification started, but if there's a path that allows the
         * modification to race with this chain rolling up, we could
         * have a problem.
         */
        _redo_task_set.reset_from(rts);

        if (is_snapshot() || has_contingent_children()) {
          /*
           * If this is a snapshot, rolling up needs to ensure that
           * it's on its parent's contingent list.  If we're racing,
           * that might put us on even if we've been taken off for a
           * conflict, but that shouldn't hurt anything.
           *
           * If this isn't a snapshot and it has contingent children,
           * it also needs to be on its parents' contingent list,
           * because subsequent changes in the parent should be
           * propagated down to its own contingent children.
           */
          ensure_on_cc_list();
        }

        gc_ptr<value> new_val = value::for_publish(closed_ts, old_val);
        _latest.try_update([=](latest_ptr_t p){
            return p.pointer() == old_val;
          },
          [=](latest_ptr_t p) {
            p.pointer() = new_val;
            p[is_closed_flag] = true;
            p[is_cached_flag] = false;
            /*
             * When we roll up, we're in sync with our parent.
             */
            p[parent_modified_flag] = false;
            p[passed_down_conflict_flag] = false;
            return p;
          });
      }
      
      void do_rollup_impl(timestamp_t closed_ts) {
        /*
         * We read the rts before _latest to make sure that we don't
         * accidentally try to clear an RTS that was added later.  (We
         * read latest, fail the short circuit, somebody else does the
         * roll-up, a modification adds an RTS, we read it, we then
         * erroneously clear it, and silently fail the update.
         * Alternatively, we could read latest, fail the short
         * circuit, read the RTS, then reread latest and try the short
         * circuit again, but I don't think that buys us anything. (It
         * potentially saves an atomic read, but at the expense of
         * often having to do an extra one.)
         */
        // std::cout << "About to roll up "
        //           << GC_THIS << " to " << get_parent()
        //           << " as of " << closed_ts
        //           << ": " << _latest.contents()->val << std::endl;
        redo_task_set_ptr_t rts = _redo_task_set.contents();
        if (rts[has_conflict_flag]) {
          /*
           * If there's a conflict, then somebody else must've
           * finished the roll-up first.
           */
          // std::cout << "Ignoring because we have a conflict" << std::endl;
          return;
        }
        
        latest_ptr_t latest = _latest.contents();
        if (latest->timestamp() >= closed_ts) {
          /*
           * Somebody else must have closed us already if we've gotten
           * another value since.  We end by changing the timestamp.
           */
          // std::cout << "Igoring because timestamp too late: " << latest->timestamp() << std::endl;
          return;
        }
        gc_ptr<value_chain> pvc = get_parent();
        /*
         * If we're rolling up, our parent must be modifiable
         */
        gc_ptr<non_ross_vc> p = std::static_pointer_cast<non_ross_vc>(pvc);

        p->receive_rollup(closed_ts,
                          [latest]() { return latest->val; },
                          [this]() { return get_context()->creation_task(); },
                          rts);

        /*
         * If we're rolling up a snapshot, this roll-up will
         * necessarily be processed before there can be any subsequent
         * change to the parent, so we don't have to worry about
         * checking whether to set the parent-modified flag.
         */

        close_chain(closed_ts, latest, rts);


      }

      static std::pair<bool, gc_ptr<value>>
        redo_closes(gc_ptr<value> v)
      {
        while (!v->marks_publish()) {
          if (!v->write_task->needs_redo()) {
            return std::make_pair(false, v);
          }
          if (v->single_modifier()) {
            /*
             * All preceding values were written by this task, which
             * must need redo.
             */
            break;
          }
          v = v->prior;
        }
        return std::make_pair(true, nullptr);
      }

      void roll_forward_impl(timestamp_t ts,
                             const gc_ptr<value> &old_val,
                             const gc_ptr<typed_msv> &in_msv)
      {
        // std::cout << "Rolling forward" << std::endl;
        /*
         * First we need to identify the value to roll to.  This can
         * be one that marks a publish or one whose write task isn't
         * being redone.
         */
        gc_ptr<value> v;
        bool just_close;
        std::tie(just_close, v) = redo_closes(old_val);
        redo_task_set_ptr_t rts = _redo_task_set.contents();
        if (just_close) {
          /*
           * We skipped over everything back to the last time we were
           * published.  So all we have to do is close and we'll be in
           * sync with our parent.  this will have the side-effect of
           * clearing any RTS.
           */
          // std::cout << "Back to publish.  Just need to close the chain" << std::endl;
          close_chain(ts, old_val, rts);
        } else {
          // std::cout << "Found a value" << std::endl;
          /*
           * We found a value that we need to make the curret value.
           *
           * If we have an RTS whose redo task needs to be redone, we
           * clear it (whether or not is has a conflict).  Note that
           * it's okay if there's an RTS for some other task.
           */
          if (rts != nullptr && rts->redo_task()->needs_redo()) {
            // std::cout << "Clearing the RTS" << std::endl;
            _redo_task_set.reset_from(rts);
            /*
             * If that failed it means that some other thread already
             * cleared it.  That's okay.  It's either clear now or it
             * was cleared and got a new value, which is correct.
             */
          }
          /*
           * Now we assert the value.  
           */
          gc_ptr<value>
            new_val = ensure_value(v->val, ts, old_val, v->write_task,
                                   in_msv, true);
          /*
           * Rolling forward brings us in sync with our parent, so we
           * can clear the parent_modified and passed_down_conflict
           * flags.
           */
          if (new_val != nullptr) {
            _latest.try_update([=](latest_ptr_t p) {
                return p.pointer() == new_val;
              },
              [=](latest_ptr_t p) {
                p[parent_modified_flag] = false;
                p[passed_down_conflict_flag] = false;
                return p;
              });
            /*
             * If that failed, another thread beat us to it.
             */
          }
        }
      }


      /*
       * There are two parts to preparing a VC for redo.  First, the
       * chain has to be put into a state such that the latest value
       * wasn't written by a task needs to be redone.  This may
       * involve closing the chain if it was only written by such
       * tasks.  Second, if there's an RTS whose redo task needs to be
       * redone, we clear it.  (This is safe, because either we're
       * closing the VC, in which case it should be clear, or we're
       * promoting an earlier value written by a non-redo task.  That
       * write was either independent of the prior value or based on
       * another such write, otherwise the task would need to be
       * redone.)
       */

      void prepare_for_redo_impl(const gc_ptr<modified_value_chain> &mvc)
      {
        if (mvc->cleared()) {
          return;
        }
        // std::cout << "Checking for roll forward on " << GC_THIS << std::endl;
        /*
         * We start by determining whether the latest value was
         * written by a task to be redone.  If it wasn't, we don't
         * need to go through the expense of actually creating the
         * modification.
         *
         * But it's possible that there's a roll-up sitting in the
         * pending queue for a context created in a task that needs to
         * be redone, so we process the roll-ups first.
         */
        gc_ptr<msv> in_msv = mvc->in_msv.lock();
        if (in_msv == nullptr) {
          return;
        }
        in_msv->process_rollups();
        /*
         * TODO: I guess it's possible that there might still be such
         * a child context in some thread that decides to publish
         * after we do the roll-up.  Need to figure out what to do in
         * that case.
         */
        gc_ptr<value> v = latest_value();
        if (!v->marks_publish() && v->write_task->needs_redo()) {
          /*
           * We will need to modify the chain, so we do it in a
           * modification to make sure we get the conflicts right.
           * This will wind up calling roll_forward().
           *
           * If we got here, we know that the MSV is one of ours,
           * since we were the one that created the MVC.
           */
          gc_ptr<typed_msv>
            tmsv = std::static_pointer_cast<typed_msv>(in_msv);
          // std::cout << "  Roll Forward needed" << std::endl;
          modify_in(tmsv, modify_op::roll_forward, val_type{});
        } else {
          /*
           * We don't have to change the value, but we still might
           * have to clear the RTS.  Note that we do that whether or
           * not the RTS has a conflict.
           */
          // std::cout << "  Roll Forward not needed" << std::endl;
          redo_task_set_ptr_t rts = _redo_task_set.contents();
          if (rts != nullptr && rts->redo_task()->needs_redo()) {
            // std::cout << "  Clearing RTS" << std::endl;
            _redo_task_set.reset_from(rts);
            /*
             * If that failed it means that somebody else already
             * cleared it somehow.  That's okay.  It's either clear
             * now or it was cleared and got a new one, which is
             * correct.
             */
          }
        }
        /*
         * At this point, if we're closed, the MVC has been taken care
         * of (either because it was closed to start or because we
         * closed it.)  Otherwise, either we left a value or another
         * one has been added.  In either case, if we try to publish
         * again, we'll need to handle this MVC (or its equivalent).
         */
        if (is_closed()) {
          mvc->clear();
        }
      }



      void add_conflict() {
        gc_ptr<redo_task_set> rts = _redo_task_set;
        if (rts != nullptr) {
          rts->set_conflict(make_gc<conflict>(rts->redo_task()),
                            get_context());
          _redo_task_set.set_flag(has_conflict_flag);
        }
      }

      bool has_conflict() const {
        return _redo_task_set.flag(has_conflict_flag);
      }

      void ensure_redo_task_set(const gc_ptr<task> &write_task,
                                const gc_ptr<task> &source_task)
      {
        _redo_task_set.try_update([](const auto &current) {
            return current == nullptr;
          }, [&](const auto &) {
            return make_gc<redo_task_set>(write_task, source_task);
          });
        ensure_on_cc_list();
      }

      void handle_task_dependencies(const gc_ptr<task> &read_task,
                                    const gc_ptr<task> &write_task)
      {
        if (read_task != write_task) {
          /*
           * We're not writing in the same task that wrote the
           * value we read.
           */
          if (read_task->get_context() == write_task->get_context()) {
            /*
             * But we're in the same context.  Add a dependency.
             */
            read_task->add_dependent_task(write_task);
          } else {
            /*
             * The contexts are different.  Create a redo task set
             * if we don't already have one.
             */
            ensure_redo_task_set(write_task, read_task);
          }
        }
      }

        
    }; // pub_vc

    template <kind K>
    struct typed_msv<K>::pub_live_vc : pub_vc {

      using base = pub_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      using base::add_conflicts_below;
      using base::add_conflict;
      using base::add_to_cc_list;
      using base::ensure_on_cc_list;
      using base::has_contingent_children;
      using base::has_conflict;
      using base::note_off_cc_list;
      using base::if_closed;
      using base::is_closed;
      using base::caches_parent_value;
      using base::get_parent;
      using base::get_context;
      using base::ensure_redo_task_set;
      using base::parent_modified;

      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::publishable, view_type::live, K);

      pub_live_vc(gc_token &gc,
                  const gc_ptr<view> &v,
                  const gc_ptr<value_chain> &p,
                  discriminator_type d = discrim)
        : base{gc, v, p, d}
      {}

      const static auto &descriptor() {
        using this_class = pub_live_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = pub_live_vc;
        void receive_conflict(core::value_chain *self, const gc_ptr<blocking_mod> &bm) override 
        { 
          self->call_non_virtual(&impl::receive_conflict_impl, bm);
        }

        void first_modification(non_ross_vc *self,
                                const gc_ptr<task> &write_task) override
        {
          self->call_non_virtual(&impl::first_modification_impl, write_task);
        }

      }; // virtuals

      void receive_conflict_impl(const gc_ptr<blocking_mod> &bm) {
        if_closed(bm,
                  [&,this]() {
                    add_conflicts_below(bm);
                  },
                  [this](){
                    add_conflict();
                  });
        note_off_cc_list();
      }


      void first_modification_impl(const gc_ptr<task> &write_task)
      {
        /*
         * Nothing to do for publishable live VCs.  I had thought that
         * I was going to call ensure_redo_task_set(), but that's done
         * in ensure_redo_task_set() inside of
         * handle_task_dependencies().
         */
      }
    }; // pub_live_vc

    template <kind K>
    struct typed_msv<K>::pub_ss_vc : pub_vc {

      using base = pub_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      using base::parent_modified;
      using base::set_parent_modified;
      using base::passed_down_conflict;
      using base::set_passed_down_conflict;
      using base::add_conflict;
      using base::add_conflicts_below;
      using base::note_off_cc_list;
      using base::add_to_cc_list;
      using base::ensure_on_cc_list;
      using base::is_closed;
      using base::if_closed;
      using base::get_context;
      using base::value_at;
      using base::get_parent;
      using base::ensure_redo_task_set;

      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::publishable, view_type::snapshot, K);

      struct setup_mod : core::modification
      {
        using discriminator_type = core::modification::discriminator_type;
        
        struct virtuals : core::modification::virtuals {
          void perform(core::modification *self) override final {
            self->call_non_virtual(&setup_mod::perform);
          }
        };

        const gc_ptr<pub_ss_vc> _vc;
        const gc_ptr<msv> _msv;
        const gc_ptr<blocking_mod> _blocker;

        setup_mod(gc_token &gc,
                  const gc_ptr<pub_ss_vc> &vc,
                  const gc_ptr<msv> &msv)
          : core::modification{gc, K},
            _vc{vc},
            _msv{msv},
            _blocker{make_gc<blocking_mod>(GC_THIS)}
        {}

        const static auto &descriptor() {
          using this_class = setup_mod;
          static gc_descriptor d =
            GC_DESC(this_class)
            .template WITH_SUPER(core::modification)
            .template WITH_FIELD(&this_class::_vc)
            .template WITH_FIELD(&this_class::_msv)
            .template WITH_FIELD(&this_class::_blocker)
            ;
          return d;
        }

        void perform() const {
          _vc->setup(_blocker, _msv);
          _blocker->mark_done();
        }
      };


      pub_ss_vc(gc_token &gc,
                const gc_ptr<view> &v,
                const gc_ptr<value_chain> &p,
                const gc_ptr<msv> &in_msv,
                discriminator_type d = discrim)
        : base{gc, v, p, d}
      {
        gc_ptr<setup_mod> mod = make_gc<setup_mod>(GC_THIS, in_msv);
        mod->perform();
      }

      void setup(const gc_ptr<blocking_mod> &bm,
                 const gc_ptr<msv> &in_msv) 
      {
        /*
         * First we block publication to make sure that a publish
         * can't publish without finishing.  This ensures that we
         * don't have to worry about the snapshot's value changing on
         * us.
         */
        get_context()->block_publication(bm);
        /*
         * Next, we insist on being a contingent child.  This means
         * that if our parent changes, we will receive a conflict and
         * our parent_modified_flag will be set.
         */
        ensure_on_cc_list();
        /*
         * Even if a modification hasn't happened yet, the parent may
         * already have been modified before we became a contingent
         * child.  We could test whether our flag has already been
         * set, but the answer will almost always be "no", so it's not
         * worth it.
         *
         * Before we can check the values, however, we have to ensure
         * that everything is rolled up.
         */
        in_msv->process_rollups();
        
        gc_ptr<value> our_value = value_at(most_recent);
        gc_ptr<value> parent_value = get_parent()->value_at(most_recent);
        if (value::differs(our_value, parent_value)) {
          /*
           * Technically, this will say "no" if the value had changed
           * and changed back.  That's fine for our purposes.
           */
          // std::cout << "S/S parent already changed at VC creation" << std::endl;
          set_parent_modified();
        }
        /*
         * Finally, we add a modified value chain to the context so
         * that before it can publish, it has to call
         * prepare_for_publish() on us so that we can pass down
         * conflicts if our parent changes while we're closed.
         */
        gc_ptr<modified_value_chain>
          mvc = make_gc<modified_value_chain>(GC_THIS, in_msv);

        get_context()->add_modification(mvc);
      }

      const static auto &descriptor() {
        using this_class = pub_ss_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = pub_ss_vc;
        void receive_conflict(core::value_chain *self, const gc_ptr<blocking_mod> &bm) override 
        { 
          self->call_non_virtual(&impl::receive_conflict_impl, bm);
        }

        void add_contingent_child(core::value_chain *self,
                                  const gc_ptr<core::value_chain> &child) override
        {
          self->call_non_virtual(&impl::add_contingent_child_impl, child);
        }

        void first_modification(non_ross_vc *self, const gc_ptr<task> &write_task) override
        {
          self->call_non_virtual(&impl::first_modification_impl, write_task);
        }

        void prepare_for_publish(core::value_chain *self,
                                 const gc_ptr<msv> &in_msv,
                                 const gc_ptr<const published_state> &new_state) override
        {
          self->call_non_virtual(&impl::prepare_for_publish_impl, in_msv, new_state);
        }
        

      }; // virtuals

      void receive_conflict_impl(const gc_ptr<blocking_mod> &bm) {
        if_closed(bm,
                  [&,this]() {
                    set_parent_modified();
                  },
                  [this](){
                    add_conflict();
                  });
        note_off_cc_list();
      }

      void add_contingent_child_impl(const gc_ptr<core::value_chain> &child) {
        if (passed_down_conflict()) {
          /*
           * If this flag is set, prepare_for_publish() has been
           * called on a closed snapshot and parent_modified was set,
           * so we induced conflicts in the contingent children.
           * do_rollup() hasn't yet been called (which will clear it),
           * so we consider the publish to still be in progress, so
           * this new child should also get a conflict.
           */
          child->receive_conflict();
        } else {
          add_to_cc_list(child);
        }
      }

      void first_modification_impl(const gc_ptr<task> &write_task)
      {
        // std::cout << "Checking for parent modification" << std::endl;
        if (parent_modified()) {
          // std::cout << "  Parent modified.  Adding conflict" << std::endl;
          /*
           * We need to have a redo task set or we won't have anyplace
           * to put the conflict.  The source task for the RTS
           * shouldn't be necessary, since we know this will never
           * roll up.
           */
          ensure_redo_task_set(write_task, nullptr);
          add_conflict();
        }
      }

      void prepare_for_publish_impl(const gc_ptr<core::msv> &in_msv,
                                    const gc_ptr<const published_state> &new_state)
      {
        /*
         * First we, do all of the normal stuff.
         */
        pub_vc::prepare_for_publish_impl(in_msv, new_state);
        /*
         * Then, if we're closed and our parent had been modified, our
         * contingent children get conflicts from the publishing.
         */
        if (is_closed() && parent_modified()) {
          set_passed_down_conflict();
          add_conflicts_below(nullptr);
        }
      }
    }; // pub_ss_vc

    template <kind K>
    struct typed_msv<K>::det_live_vc : unpub_vc {

      using base = unpub_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::detached, view_type::live, K);

      using base::ensure_on_cc_list;

      det_live_vc(gc_token &gc,
                  const gc_ptr<view> &v,
                  const gc_ptr<value_chain> &p,
                  discriminator_type d = discrim)
        : base{gc, v, p, d}
      {
        // TODO: check for parent modification since initial value and set parent_modified_flag.
      }

      const static auto &descriptor() {
        using this_class = det_live_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = det_live_vc;

        void first_modification(non_ross_vc *self, const gc_ptr<task> &write_task) override
        {
          self->call_non_virtual(&impl::first_modification_impl, write_task);
        }
      }; // virtuals

      void first_modification_impl(const gc_ptr<task> &write_task)
      {
        /*
         * I was calling ensure_on_cc_list(), but actually, this is
         * where we would take it *off* if it was cheap to do so.
         */
      }
    }; // det_live_vc

    template <kind K>
    struct typed_msv<K>::det_ss_vc : unpub_vc {

      using base = unpub_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      using base::add_to_cc_list;

      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::detached, view_type::snapshot, K);

      det_ss_vc(gc_token &gc,
                const gc_ptr<view> &v,
                const gc_ptr<value_chain> &p,
                discriminator_type d = discrim)
        : base{gc, v, p, d}
      {
        // TODO: check for parent modification since initial value and set parent_modified_flag.
      }

      const static auto &descriptor() {
        using this_class = det_ss_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = det_ss_vc;
        void receive_conflict(core::value_chain *self, const gc_ptr<blocking_mod> &bm) override 
        { 
          self->call_non_virtual(&impl::receive_conflict_impl, bm);
        }

        void add_contingent_child(core::value_chain *self,
                                  const gc_ptr<core::value_chain> &child) override
        {
          self->call_non_virtual(&impl::add_contingent_child_impl, child);
        }

        void first_modification(non_ross_vc *self, const gc_ptr<task> &write_task) override
        {
          self->call_non_virtual(&impl::first_modification_impl, write_task);
        }
      }; // virtuals

      void receive_conflict_impl(const gc_ptr<blocking_mod> &bm) {
        /*
         * A detached snapshot VC should never be on a contingent child list.
         */
        assert(ruts::fail("receive_conflict() called on detached snapshot VC"));
      }

      void add_contingent_child_impl(const gc_ptr<core::value_chain> &child) {
        /*
         * A detached snapshot doesn't have to worry about being on its parent's list.
         */
        add_to_cc_list(child);
      }
      void first_modification_impl(const gc_ptr<task> &write_task)
      {
        /*
         * A detached snapshot can only be modified by a frozen read,
         * and there's nothing to do with it.
         */
      }
    }; // det_ss_vc

    template <kind K>
    struct typed_msv<K>::ro_live_vc : unpub_vc {

      using base = unpub_vc;
      using discriminator_type = typename base::discriminator_type;
      using published_state = typename base::published_state;
      using latest_ptr_t = typename base::latest_ptr_t;

      static const discriminator_type
      discrim = value_chain::to_disc(mod_type::read_only, view_type::live, K);

      ro_live_vc(gc_token &gc,
                 const gc_ptr<view> &v,
                 const gc_ptr<value_chain> &p,
                 discriminator_type d = discrim)
        : base{gc, v, p, d}
      {
        // TODO: check for parent modification since initial value and set parent_modified_flag.
      }

      const static auto &descriptor() {
        using this_class = ro_live_vc;
        static gc_descriptor d =
          GC_DESC(this_class)
          .template WITH_SUPER(base)
          ;
        return d;
      }

      struct virtuals : base::virtuals {
        using impl = ro_live_vc;

        gc_ptr<const published_state> pub_state_after(const core::value_chain *self,
                                                      timestamp_t ts) const  override
        {
          return self->call_non_virtual(&impl::pub_state_after_impl, ts);
        }
        
        val_type modify_in(value_chain *self,
                           const gc_ptr<typed_msv> &msv,
                           modify_op op,
                           const val_type &arg,
                           ret_mode returning,
                           const gc_ptr<mod_condition> &guard) override
        {
          return self->call_non_virtual(&impl::modify_in_impl, msv,
                                        op, arg, returning, guard);
        }

        void first_modification(non_ross_vc *self, const gc_ptr<task> &write_task) override
        {
          self->call_non_virtual(&impl::first_modification_impl, write_task);
        }

      }; // virtuals

      gc_ptr<const published_state> pub_state_after_impl(timestamp_t ts) const {
        assert(ruts::fail("pub_state_after() called on read-only live VC"));
      }

      val_type modify_in_impl(const gc_ptr<typed_msv> &msv,
                              modify_op op, const val_type &arg,
                              ret_mode returning,
                              const gc_ptr<mod_condition> &guard)
      {
        if (op == modify_op::current_val || op == modify_op::frozen_current) {
          return non_ross_vc::modify_in_impl(msv, op, arg, returning, guard);
        } else {
          throw read_only_context_ex{};
        }
      }

      void first_modification_impl(const gc_ptr<task> &write_task)
      {
        /*
         * Nothing to do
         */
      }
    }; // ro_live_vc


    template <kind K>
    class typed_msv<K>::modification : public core::modification {
    public:
      static const discriminator_type discrim = K;
    private:
      enum class write_phase
      {
        block_publication,
          process_rollups,
          establish_value,
          clean_up,
          done
          };
      

      task_run_state<write_phase,
                     write_phase::block_publication,
                     write_phase::done> _run_state;
      const gc_ptr<non_ross_vc> _chain;
      const gc_ptr<typed_msv<K>> _msv;
      const gc_ptr<task> _write_task;
      const ret_mode _returning;
      const modify_op _op;
      const val_type _arg;
      const gc_ptr<mod_condition> _guard;

      val_type _ret_val;
      const gc_ptr<blocking_mod> _blocker;
      std::atomic<timestamp_t> _timestamp;
      std::atomic<bool> _modifies;
      gc_ptr<value> _old_val;
      std::atomic<gc_ptr<value>> _current;
      mod_ex_state _exception_state = mod_ex_state::no_exception;

      void block_publication() {
        /*
         * Ensure that no context can publish if such publication
         * could affect the correctness of any value chain we might
         * touch.
         *
         * First, nobody's allowed to publish into us, because if we
         * race with an incoming publication, we can get
         * out-of-order values.  If the chain doesn't have
         * publishable children, this doesn't do anything.
         */
        _chain->block_inbound_publication(_blocker);
        /*
         * At this point, we know that this modification is the only
         * one that can change the value of this value chain.  (We've
         * blocked inbound publication and the chain serializes
         * modifications.)
         *
         * When we're done installing blockers, we'll grab the
         * current timestamp, and then we'll do a roll-up, so we
         * know that all value chains will be correct as of (at
         * least) that time.  If we have to look up, we'll do so as
         * of that time, so we don't have to worry about racing with
         * anybody publishing into our ancestors.  
         *
         * If we're actually making a change (as opposed to caching
         * a read or adding zero or the like), we would have a
         * problem racing with a publish of this context, as it
         * could cause the wrong value to roll up, so we need to
         * block it from publishing, if it's publishable
         */
        bool modifies = op_traits<val_type>::modifies(_op, _arg);
        /*
         * If we're just setting and the chain is open and the current
         * value on it is the same as the one we're setting, we're not
         * really modifying, but we can't check that now because there
         * may be an unprocessed roll-up that will modify this chain.
         * But if we wait until we've process roll-ups to induce
         * conflicts and block publication into closed children, we
         * run the risk of having a grandchild publish after our
         * timestamp, when it should have gotten a conflict.  So for
         * now, we'll assume that any straight modification induces
         * conflicts.

           if (_op == modify_op::set) {
             const auto cv = _chain->latest_value();
             if (!cv->marks_publish() && cv->val == _arg) {
               modifies = false;
             }
           }
         */
        _modifies = modifies;
        if (modifies) {
          if (_chain->is_publishable()) {
            _chain->get_context()->block_publication(_blocker);
          }
          /*
           * If we modify, we may induce conflicts.  So we walk
           * through our contingent children.  Any that are open get
           * conflicts.  Any that are closed first block publication
           * into them and then their contingent children are
           * processed.
           */
          _chain->add_conflicts_below(_blocker);
        }
      }

      void process_rollups() {
        /*
         * With publication blocked, we can now grab a timestamp.
         * We also need to do a roll-up to ensure that the value
         * chains are in the proper state.
         */

        /*
         * If the timestamp is already non-zero, we don't change it.
         */
        ruts::try_change_value(_timestamp, 0, current_value_timestamp());
        _msv->process_rollups();
        /*
         * We cache the current value node here to make sure that we
         * don't try to change _latest away from anything that's been
         * added later in a racing thread.  It's okay if the flags
         * have changed.
         */
        gc_ptr<value> vn = _chain->latest_value();
        ruts::try_change_value(_current, gc_ptr<value>{}, vn);
      }

      void establish_value() {
        /*
         * We know coming in that everything in the MSV is processed
         * up through (at least) _timestamp.  That's our initial guess
         * as to what we will use, but due to pruning, we may need to
         * use a later timestamp.
         */
        timestamp_t ts = _timestamp;
        if (_op == modify_op::roll_forward) {
          /*
           * If we're rolling forward, we don't need to establish the
           * old value.
           */
          _chain->roll_forward(ts, _current, _msv);
          return;
        }
        gc_ptr<value> old_val_node;
        while (true) {
          try {
            old_val_node = _chain->needed_value(_op, _returning, ts);
            break;
          } catch (const uncertain_value_ex &ex) {
            /*
             * We found a value following a patched_around link.  The
             * timestamp in the exception is the timestamp of the
             * value node containing the patched_around prior, so we
             * know that everything's processed up to that point and
             * we can use it for our next try.  Note that this can
             * only happen when we're looking up through live chains
             * using the timestamp we guessed, since we never patch
             * around snapshot times.
             */
            ts = ex.ts;
          }
        }
        bool had_old_val = old_val_node != nullptr;
        if (had_old_val && _chain->is_publishable()) {
          assert(old_val_node->write_task != nullptr);
          gc_ptr<task> ovwt = old_val_node->write_task;
          /*
           * If we're writing in a different task than the one that
           * wrote the value we read, put a dependency between the
           * tasks if they're in the same context and create a redo
           * task set otherwise.
           */
          _chain->handle_task_dependencies(ovwt, _write_task);
        }
        
        /*
         * We can't just use the prevailing context, since this thread
         * may be helping out to remove a blocker while working in
         * another context.
         */
        gc_ptr<iso_context> ctxt = _chain->get_context();
        val_type old_val = ctxt->shadowed_val(had_old_val 
                                              ? old_val_node->val
                                              : val_type{});
        val_type computed_val;
        std::tie(computed_val, _exception_state) = op_traits<val_type>::compute(_op, old_val, _arg);
        if (_exception_state != mod_ex_state::no_exception) {
          /*
           * If there would be an exception (e.g., a divide by
           * zero), we'll throw an exception when the value is
           * recovered. We don't modify the chain.
           */
          return;
        }
        val_type new_val = ctxt->shadowed_val(computed_val);
        // std::cout << "Changing val from '" << old_val << "' to '"
        //           << new_val << "' in " << _chain << std::endl;
        _ret_val = _returning==ret_mode::resulting_val ? new_val : old_val;
        
        if (_guard != nullptr && !_guard->test(had_old_val, old_val, new_val)) {
          /*
           * If the guard failed, we set a flag to throw an exception
           * when the value is retrieved.
           */
          _exception_state = mod_ex_state::guard_failed;
        } else {
          /*
           * ensure_value() adds a new value node unless the chain is
           * open and has a value chain with the same value and task
           * (in which case it's left alone) or same timestamp and
           * task, in which case it's replaced.  
           *
           * NOTE: I need to revisit the "read in snapshot" logic we
           * used to have.  I suspect I will want to import it again,
           * but I'll need to wrap my head around it.
           *
           * ensure_value() will ensure that the chain is a contingent
           * child if it has a redo task set that doesn't have a
           * conflict.  It also ensures that the task and its context
           * are notified of the modification if it can't prove they
           * already know.
           */
          _chain->ensure_value(new_val, ts, _current,
                               _write_task, _msv, _modifies);
        }
      }

      void clean_up() {
        /*
         * Now we stop blocking context publication and
         * modifications on this MSV.  We worry about contexts
         * first, because there's more likely to be contention.
         */
        _blocker->mark_done();
        _chain->uninstall(GC_THIS);
      }

      void dispatch(write_phase p) {
        switch (p) {
        case write_phase::block_publication:
          block_publication();
          return;
        case write_phase::process_rollups:
          process_rollups();
          return;
        case write_phase::establish_value:
          establish_value();
          return;
        case write_phase::clean_up:
          clean_up();
          return;
        case write_phase::done:
        default:
          break;
        }
      }

        
    public:
      using atomic_holder = std::atomic<gc_ptr<modification>>;

      modification(gc_token &gc,
                   const gc_ptr<non_ross_vc> &vc,
                   const gc_ptr<typed_msv<K>> &msv,
                   ret_mode returning,
                   modify_op op,
                   const val_type &arg,
                   const gc_ptr<mod_condition> &guard,
                   discriminator_type d = discrim)
        : core::modification{gc,d},
          _chain{vc}, _msv{msv},
          _write_task{task::prevailing()},
          _returning{returning}, _op{op},
          _arg{arg}, _guard{guard},
          _blocker{make_gc<blocking_mod>(GC_THIS)},
          _timestamp{0}, _current{nullptr}
      {}
                   
      static const auto &descriptor() {
        static gc_descriptor d =
          GC_DESC(modification)
          .template WITH_SUPER(core::modification)
          .template WITH_FIELD(&modification::_run_state)
          .template WITH_FIELD(&modification::_chain)
          .template WITH_FIELD(&modification::_msv)
          .template WITH_FIELD(&modification::_write_task)
          .template WITH_FIELD(&modification::_returning)
          .template WITH_FIELD(&modification::_op)
          .template WITH_FIELD(&modification::_arg)
          .template WITH_FIELD(&modification::_guard)
          .template WITH_FIELD(&modification::_ret_val)
          .template WITH_FIELD(&modification::_blocker)
          .template WITH_FIELD(&modification::_timestamp)
          .template WITH_FIELD(&modification::_modifies)
          .template WITH_FIELD(&modification::_old_val)
          .template WITH_FIELD(&modification::_current)
          .template WITH_FIELD(&modification::_exception_state)
          ;
        return d;
      }

      void run() {
        _run_state.run(this, &modification::dispatch);
      }


      val_type get_value() const {
        switch (_exception_state) {
        case mod_ex_state::no_exception:
          return _ret_val;
        case mod_ex_state::divide_by_zero:
          throw div_by_zero_ex{};
        case mod_ex_state::guard_failed:
          throw guard_failure_ex{};
        default:
          throw unknown_modification_ex{static_cast<std::size_t>(_exception_state)};
        }
      }

      struct virtuals : core::modification::virtuals {
        using impl = modification;
        void perform(core::modification *self) {
          /*
           * We might as well call run() directly.
           */
          return self->call_non_virtual(&impl::run);
        }
      }; //virtuals

    }; // modification

    template <kind K>
    gc_ptr<typename typed_msv<K>::value_chain>
    typed_msv<K>::value_chain::for_view(const gc_ptr<view> &v,
                                        const gc_ptr<value_chain> &pvc,
                                        const gc_ptr<msv> &in_msv)
    {
      mod_type mt;
      view_type vt;
      std::tie(mt, vt) = v->context->get_mod_and_view_types();
      switch (vt) {
      case view_type::live:
        switch (mt) {
        case mod_type::publishable:
          return make_gc<pub_live_vc>(v, pvc);
        case mod_type::detached:
          return make_gc<det_live_vc>(v, pvc);
        case mod_type::read_only:
          return make_gc<ro_live_vc>(v, pvc);
        default:
          assert(ruts::fail("Unknown mod_type: ", mt));
          return nullptr;
        }
      case view_type::snapshot:
        switch (mt) {
        case mod_type::publishable:
          return make_gc<pub_ss_vc>(v, pvc, in_msv);
        case mod_type::detached:
          return make_gc<det_ss_vc>(v, pvc);
        case mod_type::read_only:
          return make_gc<ross_vc>(v, pvc);
        default:
          assert(ruts::fail("Unknown mod_type: ", mt));
          return nullptr;
        }
      default:
        assert(ruts::fail("Unknown view_type: ", vt));
        return nullptr;
      }
    }

    /*
     * for_view() can't be in the header file without exposing all of
     * the subclasses, so we explicitly instantiate them here.
     * There's got to be a better way than explicitly enumerating
     * each.
     */
    template
    gc_ptr<typed_msv<kind::BOOL>::value_chain>
    typed_msv<kind::BOOL>::value_chain::for_view(const gc_ptr<view> &,
                                                 const gc_ptr<value_chain> &,
                                                 const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::BYTE>::value_chain>
    typed_msv<kind::BYTE>::value_chain::for_view(const gc_ptr<view> &,
                                                 const gc_ptr<value_chain> &,
                                                 const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::UBYTE>::value_chain>
    typed_msv<kind::UBYTE>::value_chain::for_view(const gc_ptr<view> &,
                                                  const gc_ptr<value_chain> &,
                                                  const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::SHORT>::value_chain>
    typed_msv<kind::SHORT>::value_chain::for_view(const gc_ptr<view> &,
                                                  const gc_ptr<value_chain> &,
                                                  const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::USHORT>::value_chain>
    typed_msv<kind::USHORT>::value_chain::for_view(const gc_ptr<view> &,
                                                   const gc_ptr<value_chain> &,
                                                   const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::INT>::value_chain>
    typed_msv<kind::INT>::value_chain::for_view(const gc_ptr<view> &,
                                                const gc_ptr<value_chain> &,
                                                const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::UINT>::value_chain>
    typed_msv<kind::UINT>::value_chain::for_view(const gc_ptr<view> &,
                                                 const gc_ptr<value_chain> &,
                                                 const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::LONG>::value_chain>
    typed_msv<kind::LONG>::value_chain::for_view(const gc_ptr<view> &,
                                                const gc_ptr<value_chain> &,
                                                const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::ULONG>::value_chain>
    typed_msv<kind::ULONG>::value_chain::for_view(const gc_ptr<view> &,
                                                  const gc_ptr<value_chain> &,
                                                  const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::FLOAT>::value_chain>
    typed_msv<kind::FLOAT>::value_chain::for_view(const gc_ptr<view> &,
                                                  const gc_ptr<value_chain> &,
                                                  const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::DOUBLE>::value_chain>
    typed_msv<kind::DOUBLE>::value_chain::for_view(const gc_ptr<view> &,
                                                   const gc_ptr<value_chain> &,
                                                   const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::RECORD>::value_chain>
    typed_msv<kind::RECORD>::value_chain::for_view(const gc_ptr<view> &,
                                                   const gc_ptr<value_chain> &,
                                                   const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::STRING>::value_chain>
    typed_msv<kind::STRING>::value_chain::for_view(const gc_ptr<view> &,
                                                   const gc_ptr<value_chain> &,
                                                   const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::BINDING>::value_chain>
    typed_msv<kind::BINDING>::value_chain::for_view(const gc_ptr<view> &,
                                                    const gc_ptr<value_chain> &,
                                                    const gc_ptr<msv> &);
    template
    gc_ptr<typed_msv<kind::ARRAY>::value_chain>
    typed_msv<kind::ARRAY>::value_chain::for_view(const gc_ptr<view> &,
                                                  const gc_ptr<value_chain> &,
                                                  const gc_ptr<msv> &);
    template <kind K>
    using ross_vc = typename typed_msv<K>::ross_vc;
    template <kind K>
    using ro_live_vc = typename typed_msv<K>::ro_live_vc;
    template <kind K>
    using pub_live_vc = typename typed_msv<K>::pub_live_vc;
    template <kind K>
    using pub_ss_vc = typename typed_msv<K>::pub_ss_vc;
    template <kind K>
    using det_live_vc = typename typed_msv<K>::det_live_vc;
    template <kind K>
    using det_ss_vc = typename typed_msv<K>::det_ss_vc;


    void
    value_chain::init_vf_table(vf_table &t)
    {

      bind_all_kinds<ross_vc>(t);
      //t.template bind<ross_vc<kind::ULONG>>();

      bind_all_kinds<ro_live_vc>(t);
      //t.template bind<ro_live_vc<kind::ULONG>>();

      bind_all_kinds<pub_live_vc>(t);
      //t.template bind<pub_live_vc<kind::ULONG>>();

      bind_all_kinds<pub_ss_vc>(t);
      //t.template bind<pub_ss_vc<kind::ULONG>>();

      bind_all_kinds<det_live_vc>(t);
      //t.template bind<det_live_vc<kind::ULONG>>();

      bind_all_kinds<det_ss_vc>(t);
      //t.template bind<det_ss_vc<kind::ULONG>>();

    }

    template <kind K>
    using typed_modification = typename typed_msv<K>::modification;

    void
    modification::init_vf_table(vf_table &t)
    {
      //    t.template bind<typed_modification<kind::ULONG>>();
      bind_all_kinds<typed_modification>(t);
    }

    template <kind K>
    void mod_condition<K>::init_vf_table(typename mod_condition<K>::base::vf_table &t) {
      t.template bind<unbound_mod_condition<K>>();
    }

    template void mod_condition<kind::BOOL>::init_vf_table(vf_table &);
    template void mod_condition<kind::BYTE>::init_vf_table(vf_table &);
    template void mod_condition<kind::UBYTE>::init_vf_table(vf_table &);
    template void mod_condition<kind::SHORT>::init_vf_table(vf_table &);
    template void mod_condition<kind::USHORT>::init_vf_table(vf_table &);
    template void mod_condition<kind::INT>::init_vf_table(vf_table &);
    template void mod_condition<kind::UINT>::init_vf_table(vf_table &);
    template void mod_condition<kind::LONG>::init_vf_table(vf_table &);
    template void mod_condition<kind::ULONG>::init_vf_table(vf_table &);
    template void mod_condition<kind::FLOAT>::init_vf_table(vf_table &);
    template void mod_condition<kind::DOUBLE>::init_vf_table(vf_table &);
    template void mod_condition<kind::STRING>::init_vf_table(vf_table &);
    template void mod_condition<kind::RECORD>::init_vf_table(vf_table &);
    template void mod_condition<kind::BINDING>::init_vf_table(vf_table &);
    template void mod_condition<kind::ARRAY>::init_vf_table(vf_table &);
    template void mod_condition<kind::NAMESPACE>::init_vf_table(vf_table &);
    
    // template <>
    // void mod_condition<kind::INT>::init_vf_table(vf_table &t) {
    //   t.bind<unbound_mod_condition<kind::INT>>();
    // }
  } // core
} // mds
